\section{Literature}

The book written by \cite{BookIA} presents some basic concepts necessary to start in the field of artificial intelligence (AI).
AI models have been thought of since the early days of computing. It has always been aspired to build an algorithm
that would self-model itself depending on the problem, to have the best possible solution
and that would be able to increase its own accuracy by simply needing a larger input, without the need to modify
the code itself.

According to \cite{AntColonyOptimization}, the concept of algorithms
inspired by the colony behaviors of ants and similar insects emerged in the 1990s.
Noticing details in the way ants organize themselves to find better
paths to achieve their goals, inspired several researchers to design algorithms that imitate ants behavior as a way
of optimization for the field of artificial intelligence.

When programming artificial intelligence (AI) systems, a predominant concern often involves the size of the input data for training, although this is not universally applicable.
An AI that always needs large inputs to get good results needs to make good use of the resources available on the machine.
Therefore, modeling this program taking advantage of parallel computing is essential for good use of these resources.
The performance difference between the sequential version and the parallel version is so significant that designing the algorithms
already thinking about making them parallel can make a huge difference as commented in \cite{SequentialVSParallel}.

As presented by \cite{ParallelComputingCUDA}, several computational problems can be optimized on GPUs.
The use of CUDA for parallel programming of massive amounts of data becomes extremely necessary, since
Nvidia graphics cards can be up to 250 times faster than a parallel version on Intel CPU \cite{ParallelComputingCUDA}.
Graphics cards have a great capacity to calculate large amounts of data simultaneously and artificial intelligence
is an application that fits perfectly for this purpose.

Algorithms for selecting the best instance, like the \emph{K-Means}, have always been a reference when discussing clustering algorithms. In the article written by \cite{KmeansAlgorithm},
it is shown how there are several extremely efficient implementations for this algorithm and how the complexity order can be diminished, as shown in Figure \ref{fig:complexitykmeans}.

\begin{figure}[!ht]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Complexity & \emph{K-Means} & \emph{Constrained-K-Means} & \emph{X-Means} \\
        \hline
        Time & $O(n^2)$ & $O(kn)$ & $O(n\log k_{max})$ \\
        \hline
        Space & $O((n+k)d)$ & $O((n+k)d)$ & $O((n+k)d)$ \\
        \hline
    \end{tabular}
    \caption[a]{Complexity of some \emph{K-Means} implementations\footnotemark.}
    \label{fig:complexitykmeans}
\end{figure}

\footnotetext{Taken from the article: \cite{KmeansAlgorithm}.}
