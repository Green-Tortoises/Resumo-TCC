\subsection{Method} \label{Method}

Using the mentioned tools, it will be necessary to construct a modified ACO algorithm to enable its parallel execution on GPUs with great perfomance and scalability. The initial algorithm model considered is to calculate ant movements independently. This allows for the simultaneous treatment of a large set of ants at once. When these ants finish searching for the best path, they return, and all the data is processed. Then, more ants are sent to calculate the new best path, and this process continues until the entire database is processed.

It will be necessary to measure the time it takes for each database to process all the paths. With this data, various charts was produced containing the number of instances being processed over time. By analyzing these charts, it is possible to identify areas where GPU processing are much more optimized than CPU for massive parallel calculus.

These code snippets below are parts of the most important function $ant\_action$ \footnote{Code can be seen here: \cite{santiago_parallel_aco}} :


\begin{lstlisting}[language=c++]
rocrand_state_xorwow state;
rocrand_init(random_numbers_seed, ant, 0, &state);

int ajk;
for (int j = 0; j < num_inst; j++) {
    ajk = rocrand(&state) % 100;

    if (the_colony[ant*num_inst+j] == -1) {
        if (ajk >= 40)
            the_colony[ant*num_inst+j] = 1;
        else
            the_colony[ant*num_inst+j] = 0;
    }
}
\end{lstlisting}

This part was built to produce a path for the ant walking through all the data available.
This algorithm by definition uses randomized numbers for choosing if it takes a path or not.
ROCrand \cite{rocrand} was used to produce pseudo random numbers for all the ants independently.
Considering that all GPU threads need to get different values for all the different ants. So each ant
can take a different path to the goal. the next part is going to be the measurements to see if
this algorithm has good accuracy.

\begin{lstlisting}[language=c++]
for (int inst_tst = 0; inst_tst < num_inst_test; inst_tst++);
\end{lstlisting}

The next two function parts below is inside this \emph{for} above.
This for runs through all the instances available in the dataset and choose
a random path to take. The ant with the best accuracy found will return its value
to be displayed.

\begin{lstlisting}[language=c++]
// KNN process
float menor_distance = FLT_MAX;
float current_class = -1.0f;

for (int inst_select = 0; inst_select < num_inst; inst_select++) {
    if ((ant*num_inst+inst_select) < num_inst && the_colony[ant*num_inst+inst_select] == 1) {
        float dist = distance(&tst_matrix[inst_tst*num_attr_tst], &matrix[inst_select*num_attr], num_attr_tst-1);
        if (dist < menor_distance) {
            menor_distance = dist;
            current_class = matrix[inst_select*num_attr+num_attr-1];
        }
    }
}
if (current_class == tst_matrix[inst_tst*num_attr_tst+num_attr_tst-1]) {
    matches[num_inst_test*ant + inst_tst] = 1;
} else {
    matches[num_inst_test*ant+inst_tst] = 0;
}
\end{lstlisting}

This code below is used to check what would be if an ant took all the paths possible. That's important to check
if the algorithm accuracy is valid. Tooking all the paths makes the accuracy smaller than the best ant.

\begin{lstlisting}[language=c++]
// KNN of a "perfect" ant
float menor_distance_conjunto_completo = FLT_MAX;
float current_class_conjunto_completo = -1.0f;

for (int inst_select = 0; inst_select < num_inst; inst_select++) {
    float dist_completo = distance(&tst_matrix[inst_tst*num_attr_tst], &matrix[inst_select*num_attr], num_attr_tst-1);

    if (dist_completo < menor_distance_conjunto_completo) {
        menor_distance_conjunto_completo = dist_completo;
        current_class_conjunto_completo = matrix[inst_select*num_attr+num_attr-1];
    }
}
if (current_class_conjunto_completo == tst_matrix[inst_tst*num_attr_tst+num_attr_tst-1]) {
    matches_completo[num_inst_test*ant+inst_tst] = 1;
} else {
    matches_completo[num_inst_test*ant+inst_tst] = 0;
}
\end{lstlisting}

For compiling the code these flags were used:

\begin{lstlisting}
CPU: gcc -O2 -fopt-info-vec-optimized -fopenmp acopar3otim.c -o acopar3otimCPU -lm
GPU: hipcc -O2 -lrocrand -Wall -pedantic acopar3otim.cpp -o acopar3otim
\end{lstlisting}

It's important to notice that the CPU version actually runs in parallel all
regions that has no data dependency. It uses device map as well, so if the computer
supports running a loop inside any GPU available it is going to split the work between CPU and GPU.
It uses openmp as the multithreading library. Openmp has the advantage of being easy
to program using it, as simples as adding the correct directives above the code, but
has the disavantage of not being able to control the data flow inside the GPU as much
as coding directly in ROCm. Another big problem is, the code is not written thinking
of the parallelism, so there are too many memory synchronization between threads
that makes the code much slower.

For this
